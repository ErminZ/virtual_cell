{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d65d233-69cb-4534-9e9e-3317806cee94",
   "metadata": {},
   "source": [
    "# Refernece using state\n",
    "## input h5ad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7272138d-4142-4489-9ba6-6721d3b07f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "os.environ['MPLBACKEND'] = 'Agg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c64b6e9-3b2c-4afb-be33-464e674b6570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'h5py._hl.files.File'>\n",
      "Keys in root: ['X', 'layers', 'obs', 'obsm', 'obsp', 'uns', 'var', 'varm', 'varp']\n",
      "Keys in obsm: []\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mobsm\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mKeys in obsm:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlist\u001b[39m(f[\u001b[33m'\u001b[39m\u001b[33mobsm\u001b[39m\u001b[33m'\u001b[39m].keys()))\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mKeys in X:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlist\u001b[39m(\u001b[43mf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m()))\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNo \u001b[39m\u001b[33m'\u001b[39m\u001b[33mobsm\u001b[39m\u001b[33m'\u001b[39m\u001b[33m group found\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Dataset' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "# Check the structure of our sample H5 files\n",
    "with h5py.File('virtual_cell/predicted_only_10.h5ad', 'r') as f:\n",
    "    print(type(f))\n",
    "    print(\"Keys in root:\", list(f.keys()))\n",
    "    if 'obsm' in f:\n",
    "        print(\"Keys in obsm:\", list(f['obsm'].keys()))\n",
    "        print(\"Keys in X:\", list(f['X'].keys()))\n",
    "    else:\n",
    "        print(\"No 'obsm' group found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f7d940c-ea07-488d-9187-5dbab9fe2df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_only_10.h5ad\n"
     ]
    }
   ],
   "source": [
    "! ls virtural_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcc48fec-4037-4ed8-b605-856a97d76afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'h5py._hl.files.File'>\n",
      "Keys in root: ['X', 'layers', 'obs', 'obsm', 'obsp', 'uns', 'var', 'varm', 'varp']\n",
      "Keys in obsm: []\n",
      "Keys in X: ['data', 'indices', 'indptr']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check the structure of one of COLAB H5 files\n",
    "with h5py.File('/workspace/training_dataset/competition_support_set/competition_train.h5', 'r') as f:\n",
    "    print(type(f))\n",
    "    print(\"Keys in root:\", list(f.keys()))\n",
    "    if 'obsm' in f:\n",
    "        print(\"Keys in obsm:\", list(f['obsm'].keys()))\n",
    "        print(\"Keys in X:\", list(f['X'].keys()))\n",
    "    else:\n",
    "        print(\"No 'obsm' group found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99df2e8d-2a6c-4c94-b265-96b462f593d9",
   "metadata": {},
   "source": [
    "## Model download\n",
    "### 1. SE600M Download trained parameteres \n",
    "### 2. var_dims.pkl from ST-Tahoe [reference](https://github.com/ArcInstitute/state/issues/133)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e924d1b2-e24d-42c9-84e4-19af0b57815d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading all files from arcinstitute/SE-600M...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c39756a19034ebc9d4d068a58f7f47a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 11 files:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3e81aa324ae4e4ab31d1848a4606200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LICENSE.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8710970910c14185ba19840559f43af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "protein_embeddings.pt:   0%|          | 0.00/411M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c741b05ffd411f97e71303367404b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MODEL_ACCEPTABLE_USE_POLICY.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8b8915e84148d3b66d781211352e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a63829c9c9f1479bb856a7866243bb78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MODEL_LICENSE.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "311056f8d0e8413b94cb5db17d862711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.yaml: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be7908181b94700a9a87d9e349324c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/823 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef0e68cfeb044e3adea0e744f360aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.82G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d95d43cf07134b60b962c50fdc2da8b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "se600m_epoch16.ckpt:   0%|          | 0.00/11.5G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933a6fde887742ffbc76eddb968cb897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "se600m_epoch4.safetensors:   0%|          | 0.00/2.82G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3b648585b440b9b7aad41fd3be33a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "se600m_epoch4.ckpt:   0%|          | 0.00/11.5G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "# Define the repository and local directory\n",
    "repo_id = \"arcinstitute/SE-600M\"\n",
    "local_dir = \"virtual_cell/SE-600M/\"\n",
    "\n",
    "# Download all files from the repository\n",
    "print(f\"Downloading all files from {repo_id}...\")\n",
    "local_path = snapshot_download(\n",
    "    repo_id=repo_id,\n",
    "    local_dir=local_dir,\n",
    "    local_dir_use_symlinks=False  # This ensures actual files are downloaded, not symlinks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0637279d-bb96-4476-a381-f7051e2fd5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d4b76b11874b70925e3c17bcef7918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "var_dims.pkl:   0%|          | 0.00/206k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded to: /root/.cache/huggingface/hub/models--arcinstitute--ST-Tahoe/snapshots/6fd3edc556f8587793035f907eb03a48867ae09f/var_dims.pkl\n"
     ]
    }
   ],
   "source": [
    "# SE600M doesn't contain var_dims.pkl but ST-Tahoe does and should be the model used for inference\n",
    "\n",
    "repo_id = \"arcinstitute/ST-Tahoe\"\n",
    "filename = \"var_dims.pkl\"\n",
    "\n",
    "# Download the file, it will be cached and its local path returned\n",
    "local_path = hf_hub_download(repo_id=repo_id, filename=filename)\n",
    "\n",
    "print(f\"File downloaded to: {local_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b02c6661-e842-4ab7-8a0f-99c1c755fc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE.md\t\t\tprotein_embeddings.pt\n",
      "MODEL_ACCEPTABLE_USE_POLICY.md\tse600m_epoch16.ckpt\n",
      "MODEL_LICENSE.md\t\tse600m_epoch4.ckpt\n",
      "README.md\t\t\tse600m_epoch4.safetensors\n",
      "config.yaml\t\t\tvar_dims.pkl\n",
      "model.safetensors\n"
     ]
    }
   ],
   "source": [
    "! ls virtual_cell/SE-600M/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ca2fb0-8dfd-4a6b-8548-9da3eac71b99",
   "metadata": {},
   "source": [
    "## Inferecne our sample\n",
    "### Killed reason: 1.My MacPro (16G memory) might not enough memory for inference run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6d35d638-4beb-4e30-b826-3a4fdec84d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:state._cli._tx._infer:Loaded config from virtual_cell/SE-600M/config.yaml\n",
      "INFO:state._cli._tx._infer:Loading model from checkpoint: virtual_cell/SE-600M/se600m_epoch16.ckpt\n",
      "Killed\n"
     ]
    }
   ],
   "source": [
    "! state tx infer \\\n",
    "  --output \"virtual_cell/prediction_SE600M_250618/prediction_only_10.h5ad\" \\\n",
    "  --model_dir virtual_cell/SE-600M \\\n",
    "  --checkpoint virtual_cell/SE-600M/se600m_epoch16.ckpt \\\n",
    "  --adata \"virtual_cell/predicted_only_10.h5ad\" \\\n",
    "  --pert_col \"target_gene\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2e01f5a7-11e1-4f54-88f0-b68bc33a2600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:state._cli._emb._transform:Using model checkpoint: virtual_cell/SE-600M/se600m_epoch4.ckpt\n",
      "INFO:state._cli._emb._transform:Creating inference object\n",
      "INFO:state._cli._emb._transform:Loading model from checkpoint: virtual_cell/SE-600M/se600m_epoch4.ckpt\n",
      "Killed\n"
     ]
    }
   ],
   "source": [
    "# embedding first, but not solving the error.\n",
    "! state emb transform \\\n",
    "  --model-folder virtual_cell/SE-600M \\\n",
    "  --input virtual_cell/predicted_only_10.h5ad \\\n",
    "  --output virtual_cell/predicted_only_10_emb.h5ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae4aea0-8413-4b6d-81c7-141ae0067aee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60160cd2-9bd3-48a4-82a2-0459c2251b76",
   "metadata": {},
   "source": [
    "## Wrong model ST-Parse logs for learning structure for ours and COLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96dc00f4-6e53-43b1-9ec6-e03e25983d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:state._cli._tx._infer:Loaded config from virtual_cell/ST_Parse/config.yaml\n",
      "INFO:state._cli._tx._infer:Loading model from checkpoint: virtual_cell/ST_Parse/final.ckpt\n",
      "PertSetsPerturbationModel(\n",
      "  (loss_fn): SamplesLoss()\n",
      "  (gene_decoder): LatentToGeneDecoder(\n",
      "    (decoder): Sequential(\n",
      "      (0): Linear(in_features=2000, out_features=1024, bias=True)\n",
      "      (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (2): GELU(approximate='none')\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "      (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (5): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (6): GELU(approximate='none')\n",
      "      (7): Dropout(p=0.1, inplace=False)\n",
      "      (8): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (9): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (10): GELU(approximate='none')\n",
      "      (11): Dropout(p=0.1, inplace=False)\n",
      "      (12): Linear(in_features=512, out_features=2000, bias=True)\n",
      "      (13): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (pert_encoder): Sequential(\n",
      "    (0): Linear(in_features=91, out_features=1440, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "    (4): GELU(approximate='none')\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "    (7): GELU(approximate='none')\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "  )\n",
      "  (basal_encoder): Sequential(\n",
      "    (0): Linear(in_features=2000, out_features=1440, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "    (4): GELU(approximate='none')\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "    (7): GELU(approximate='none')\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "  )\n",
      "  (transformer_backbone): LlamaBidirectionalModel(\n",
      "    (embed_tokens): Embedding(32000, 1440, padding_idx=0)\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=1440, out_features=1440, bias=False)\n",
      "          (k_proj): Linear(in_features=1440, out_features=1440, bias=False)\n",
      "          (v_proj): Linear(in_features=1440, out_features=1440, bias=False)\n",
      "          (o_proj): Linear(in_features=1440, out_features=1440, bias=False)\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=1440, out_features=4416, bias=False)\n",
      "          (up_proj): Linear(in_features=1440, out_features=4416, bias=False)\n",
      "          (down_proj): Linear(in_features=4416, out_features=1440, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((1440,), eps=1e-06)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((1440,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((1440,), eps=1e-06)\n",
      "    (rotary_emb): NoRoPE()\n",
      "  )\n",
      "  (project_out): Sequential(\n",
      "    (0): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "    (4): GELU(approximate='none')\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "    (7): GELU(approximate='none')\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=1440, out_features=2000, bias=True)\n",
      "  )\n",
      "  (batch_encoder): Embedding(18, 1440)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "INFO:state.tx.models.base:Loaded decoder from checkpoint decoder_cfg: {'latent_dim': 2000, 'gene_dim': 2000, 'hidden_dims': [1024, 1024, 512], 'dropout': 0.1, 'residual_decoder': False}\n",
      "INFO:state._cli._tx._infer:Loading AnnData from: virtual_cell/predicted_only_10.h5ad\n",
      "INFO:state._cli._tx._infer:Using adata.X as input features: shape (500, 18080)\n",
      "INFO:state._cli._tx._infer:Perturbation tensor shape: torch.Size([500, 91])\n",
      "INFO:state._cli._tx._infer:Data module has 91 perturbations in mapping\n",
      "INFO:state._cli._tx._infer:First 10 perturbations in data module: [np.str_('4-1BBL'), np.str_('ADSF'), np.str_('APRIL'), np.str_('BAFF'), np.str_('C3a'), np.str_('C5a'), np.str_('CD27L'), np.str_('CD30L'), np.str_('CD40L'), np.str_('CT-1')]\n",
      "INFO:state._cli._tx._infer:AnnData has 50 unique perturbations\n",
      "INFO:state._cli._tx._infer:First 10 perturbations in AnnData: ['ACLY', 'ANXA6', 'ARPC2', 'CENPB', 'COX4I1', 'COX6C', 'CSK', 'CTSV', 'CXCL12', 'DOT1L']\n",
      "INFO:state._cli._tx._infer:Overlap between AnnData and data module: 0 perturbations\n",
      "WARNING:state._cli._tx._infer:Missing perturbations: ['SUPV3L1', 'UQCRB', 'COX4I1', 'MAT2A', 'EIF3H', 'MAX', 'CTSV', 'ACLY', 'KLHDC2', 'EHMT1']\n",
      "INFO:state._cli._tx._infer:Control perturbation in data module: 'PBS'\n",
      "INFO:state._cli._tx._infer:Matched 0 out of 500 perturbations\n",
      "INFO:state._cli._tx._infer:Running inference on 500 samples in 1 batches of size 512 (model's cell_sentence_len)...\n",
      "Processing samples:   0%|                          | 0/500 [00:00<?, ?samples/s]Traceback (most recent call last):\n",
      "  File \"/root/.local/bin/state\", line 10, in <module>\n",
      "    sys.exit(main())\n",
      "             ^^^^^^\n",
      "  File \"/root/.local/share/uv/tools/arc-state/lib/python3.11/site-packages/state/__main__.py\", line 68, in main\n",
      "    run_tx_infer(args)\n",
      "  File \"/root/.local/share/uv/tools/arc-state/lib/python3.11/site-packages/state/_cli/_tx/_infer.py\", line 203, in run_tx_infer\n",
      "    batch_preds = model.predict_step(batch, batch_idx=batch_idx, padded=False)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/tools/arc-state/lib/python3.11/site-packages/state/tx/models/pert_sets.py\", line 552, in predict_step\n",
      "    latent_output = self.forward(batch, padded=padded)  # shape [B, ...]\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/tools/arc-state/lib/python3.11/site-packages/state/tx/models/pert_sets.py\", line 297, in forward\n",
      "    basal = batch[\"ctrl_cell_emb\"].reshape(1, -1, self.input_dim)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: shape '[1, -1, 2000]' is invalid for input of size 9256960\n",
      "Processing samples:   0%|                          | 0/500 [00:00<?, ?samples/s]\n"
     ]
    }
   ],
   "source": [
    "! state tx infer \\\n",
    "  --output \"virtual_cell/prediction_250617/prediction_only_10.h5ad\" \\\n",
    "  --model_dir virtual_cell/ST_Parse \\\n",
    "  --checkpoint virtual_cell/ST_Parse/final.ckpt \\\n",
    "  --adata \"virtual_cell/predicted_only_10.h5ad\" \\\n",
    "  --pert_col \"target_gene\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71f6cc6-aecf-41b3-9ac8-c0f1e07aa8c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c10d444d-f5e5-4252-9c70-b77350f7632c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:state._cli._tx._infer:Loaded config from virtual_cell/ST_Parse/config.yaml\n",
      "INFO:state._cli._tx._infer:Loading model from checkpoint: virtual_cell/ST_Parse/final.ckpt\n",
      "PertSetsPerturbationModel(\n",
      "  (loss_fn): SamplesLoss()\n",
      "  (gene_decoder): LatentToGeneDecoder(\n",
      "    (decoder): Sequential(\n",
      "      (0): Linear(in_features=2000, out_features=1024, bias=True)\n",
      "      (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (2): GELU(approximate='none')\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "      (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (5): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (6): GELU(approximate='none')\n",
      "      (7): Dropout(p=0.1, inplace=False)\n",
      "      (8): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (9): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (10): GELU(approximate='none')\n",
      "      (11): Dropout(p=0.1, inplace=False)\n",
      "      (12): Linear(in_features=512, out_features=2000, bias=True)\n",
      "      (13): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (pert_encoder): Sequential(\n",
      "    (0): Linear(in_features=91, out_features=1440, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "    (4): GELU(approximate='none')\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "    (7): GELU(approximate='none')\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "  )\n",
      "  (basal_encoder): Sequential(\n",
      "    (0): Linear(in_features=2000, out_features=1440, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "    (4): GELU(approximate='none')\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "    (7): GELU(approximate='none')\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "  )\n",
      "  (transformer_backbone): LlamaBidirectionalModel(\n",
      "    (embed_tokens): Embedding(32000, 1440, padding_idx=0)\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=1440, out_features=1440, bias=False)\n",
      "          (k_proj): Linear(in_features=1440, out_features=1440, bias=False)\n",
      "          (v_proj): Linear(in_features=1440, out_features=1440, bias=False)\n",
      "          (o_proj): Linear(in_features=1440, out_features=1440, bias=False)\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=1440, out_features=4416, bias=False)\n",
      "          (up_proj): Linear(in_features=1440, out_features=4416, bias=False)\n",
      "          (down_proj): Linear(in_features=4416, out_features=1440, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((1440,), eps=1e-06)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((1440,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((1440,), eps=1e-06)\n",
      "    (rotary_emb): NoRoPE()\n",
      "  )\n",
      "  (project_out): Sequential(\n",
      "    (0): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "    (4): GELU(approximate='none')\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "    (7): GELU(approximate='none')\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=1440, out_features=2000, bias=True)\n",
      "  )\n",
      "  (batch_encoder): Embedding(18, 1440)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "INFO:state.tx.models.base:Loaded decoder from checkpoint decoder_cfg: {'latent_dim': 2000, 'gene_dim': 2000, 'hidden_dims': [1024, 1024, 512], 'dropout': 0.1, 'residual_decoder': False}\n",
      "INFO:state._cli._tx._infer:Loading AnnData from: training_dataset/competition_support_set/competition_val_template.h5ad\n",
      "INFO:state._cli._tx._infer:Using adata.X as input features: shape (98927, 18080)\n",
      "INFO:state._cli._tx._infer:Perturbation tensor shape: torch.Size([98927, 91])\n",
      "INFO:state._cli._tx._infer:Data module has 91 perturbations in mapping\n",
      "INFO:state._cli._tx._infer:First 10 perturbations in data module: [np.str_('4-1BBL'), np.str_('ADSF'), np.str_('APRIL'), np.str_('BAFF'), np.str_('C3a'), np.str_('C5a'), np.str_('CD27L'), np.str_('CD30L'), np.str_('CD40L'), np.str_('CT-1')]\n",
      "INFO:state._cli._tx._infer:AnnData has 51 unique perturbations\n",
      "INFO:state._cli._tx._infer:First 10 perturbations in AnnData: ['ACLY', 'ANXA6', 'ARPC2', 'CENPB', 'COX4I1', 'COX6C', 'CSK', 'CTSV', 'CXCL12', 'DOT1L']\n",
      "INFO:state._cli._tx._infer:Overlap between AnnData and data module: 0 perturbations\n",
      "WARNING:state._cli._tx._infer:Missing perturbations: ['FUBP1', 'ACLY', 'ANXA6', 'SMARCB1', 'STRAP', 'HDAC8', 'SUPV3L1', 'HDAC3', 'MAT2A', 'TCF7L2']\n",
      "INFO:state._cli._tx._infer:Control perturbation in data module: 'PBS'\n",
      "INFO:state._cli._tx._infer:Matched 0 out of 98927 perturbations\n",
      "INFO:state._cli._tx._infer:Running inference on 98927 samples in 194 batches of size 512 (model's cell_sentence_len)...\n",
      "Processing samples:   0%|                        | 0/98927 [00:00<?, ?samples/s]Traceback (most recent call last):\n",
      "  File \"/root/.local/bin/state\", line 10, in <module>\n",
      "    sys.exit(main())\n",
      "             ^^^^^^\n",
      "  File \"/root/.local/share/uv/tools/arc-state/lib/python3.11/site-packages/state/__main__.py\", line 68, in main\n",
      "    run_tx_infer(args)\n",
      "  File \"/root/.local/share/uv/tools/arc-state/lib/python3.11/site-packages/state/_cli/_tx/_infer.py\", line 203, in run_tx_infer\n",
      "    batch_preds = model.predict_step(batch, batch_idx=batch_idx, padded=False)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/tools/arc-state/lib/python3.11/site-packages/state/tx/models/pert_sets.py\", line 552, in predict_step\n",
      "    latent_output = self.forward(batch, padded=padded)  # shape [B, ...]\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/tools/arc-state/lib/python3.11/site-packages/state/tx/models/pert_sets.py\", line 297, in forward\n",
      "    basal = batch[\"ctrl_cell_emb\"].reshape(1, -1, self.input_dim)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: shape '[1, -1, 2000]' is invalid for input of size 9256960\n",
      "Processing samples:   0%|                        | 0/98927 [00:02<?, ?samples/s]\n"
     ]
    }
   ],
   "source": [
    "# using COLAB input for testing\n",
    "! state tx infer \\\n",
    "  --output \"virtual_cell/prediction_250617/prediction_only_10.h5ad\" \\\n",
    "  --model_dir virtual_cell/ST_Parse \\\n",
    "  --checkpoint virtual_cell/ST_Parse/final.ckpt \\\n",
    "  --adata \"training_dataset/competition_support_set/competition_val_template.h5ad\" \\\n",
    "  --pert_col \"target_gene\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c94b19d-79cb-4f96-a5b7-e5e03d0e157f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30b5d36-776e-450b-a13e-014282f360b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01408d1-045f-4dd8-be37-467ddd4130fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699c5225-af4d-4771-975d-3ed7d33ff823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af66a223-2a8d-4885-b908-2746a003b02f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea10e3e-2de1-4d8d-b394-6339db28e0d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df4e32a-0a5a-499d-88ab-ad676f985868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdd165d-8175-4218-8fb5-9812a2d99e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16103607-09ba-47d5-9b7f-0a6c7d4554c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954fed52-5e2c-42df-bacb-495d03b94323",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
