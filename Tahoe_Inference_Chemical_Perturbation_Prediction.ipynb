{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d65d233-69cb-4534-9e9e-3317806cee94",
   "metadata": {},
   "source": [
    "# Tahoe Inference - Chemical Perturbation Prediction\n",
    "This notebook runs State model inference to predict chemical perturbation effects on single cells. We'll test the reproducibility of Tahoe results using our prepared dataset.\n",
    "## input h5ad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7272138d-4142-4489-9ba6-6721d3b07f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "os.environ['MPLBACKEND'] = 'Agg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c64b6e9-3b2c-4afb-be33-464e674b6570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'h5py._hl.files.File'>\n",
      "Keys in root: ['X', 'layers', 'obs', 'obsm', 'obsp', 'uns', 'var', 'varm', 'varp']\n",
      "Keys in obsm: []\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mobsm\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mKeys in obsm:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlist\u001b[39m(f[\u001b[33m'\u001b[39m\u001b[33mobsm\u001b[39m\u001b[33m'\u001b[39m].keys()))\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mKeys in X:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlist\u001b[39m(\u001b[43mf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m()))\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNo \u001b[39m\u001b[33m'\u001b[39m\u001b[33mobsm\u001b[39m\u001b[33m'\u001b[39m\u001b[33m group found\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Dataset' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "# Check the structure of our sample H5 files\n",
    "with h5py.File('virtual_cell/predicted_only_10.h5ad', 'r') as f:\n",
    "    print(type(f))\n",
    "    print(\"Keys in root:\", list(f.keys()))\n",
    "    if 'obsm' in f:\n",
    "        print(\"Keys in obsm:\", list(f['obsm'].keys()))\n",
    "        print(\"Keys in X:\", list(f['X'].keys()))\n",
    "    else:\n",
    "        print(\"No 'obsm' group found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f7d940c-ea07-488d-9187-5dbab9fe2df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_only_10.h5ad\n"
     ]
    }
   ],
   "source": [
    "! ls virtural_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcc48fec-4037-4ed8-b605-856a97d76afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'h5py._hl.files.File'>\n",
      "Keys in root: ['X', 'layers', 'obs', 'obsm', 'obsp', 'uns', 'var', 'varm', 'varp']\n",
      "Keys in obsm: []\n",
      "Keys in X: ['data', 'indices', 'indptr']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check the structure of one of COLAB H5 files\n",
    "with h5py.File('/workspace/training_dataset/competition_support_set/competition_train.h5', 'r') as f:\n",
    "    print(type(f))\n",
    "    print(\"Keys in root:\", list(f.keys()))\n",
    "    if 'obsm' in f:\n",
    "        print(\"Keys in obsm:\", list(f['obsm'].keys()))\n",
    "        print(\"Keys in X:\", list(f['X'].keys()))\n",
    "    else:\n",
    "        print(\"No 'obsm' group found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99df2e8d-2a6c-4c94-b265-96b462f593d9",
   "metadata": {},
   "source": [
    "## Model download\n",
    "### 1. SE600M Download trained parameteres \n",
    "### 2. var_dims.pkl from ST-Tahoe [reference](https://github.com/ArcInstitute/state/issues/133)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b3ab673-13ec-4757-9094-f8bf163b1d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    }
   ],
   "source": [
    "! pwd # $(pwd):/workspace where I run jupyter locally /Users/ermin/PycharmProjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2eae48f-47d2-418d-953b-932967f56adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/site-packages (from huggingface_hub) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from huggingface_hub) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/site-packages (from huggingface_hub) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/site-packages (from huggingface_hub) (4.12.2)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface_hub)\n",
      "  Downloading hf_xet-1.1.9-cp37-abi3-manylinux_2_28_aarch64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->huggingface_hub) (2022.12.7)\n",
      "Downloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.9-cp37-abi3-manylinux_2_28_aarch64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: hf-xet, huggingface_hub\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [huggingface_hub] [huggingface_hub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed hf-xet-1.1.9 huggingface_hub-0.34.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install huggingface_hub # install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e924d1b2-e24d-42c9-84e4-19af0b57815d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading all files from arcinstitute/ST-Tahoe...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:982: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
      "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "345cdacc2bee45bd8c4dea53cac3f490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 14 files:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0ba910577134d15afd70df191b8a004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b30a886f3704b8d893657e94a2b54d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cell_type_onehot_map.pkl:   0%|          | 0.00/518k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "694df134cb6e447590b2228074fe4706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MODEL_ACCEPTABLE_USE_POLICY.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9594ab20b95149c284c83dd2469f7893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batch_onehot_map.pkl:   0%|          | 0.00/16.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfd6a61fac1d46baaa8706c6d53f2e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MODEL_LICENSE.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0292e5750bc74be6947934b0f1e7518c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.yaml: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b92d9e1c29e4d3889cfbb60863685d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a30220757847d69476b525821fc1cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LICENSE.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d91b84436fc4bc5a15ffc984495634a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data_module.torch:   0%|          | 0.00/1.90k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ec76a47d2f4b1dbf87bad80009cc33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pert_onehot_map.pt:   0%|          | 0.00/5.50M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5866cb3b4f45a08ca675105d968c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "final.ckpt:   0%|          | 0.00/3.01G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8798ad8e3fc047d6a4bfee6f21c6e6ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "final_from_preprint.ckpt:   0%|          | 0.00/3.07G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c540b2222f94b0695e2137a5bd8d359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "var_dims.pkl:   0%|          | 0.00/206k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07792b86f5284defb7fbbe766daeeb4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "wandb_path.txt:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "# Define the repository and local directory\n",
    "repo_id = \"arcinstitute/ST-Tahoe\"\n",
    "local_dir = \"virtual_cell/ST-Tahoe\"\n",
    "\n",
    "# Download all files from the repository\n",
    "print(f\"Downloading all files from {repo_id}...\")\n",
    "local_path = snapshot_download(\n",
    "    repo_id=repo_id,\n",
    "    local_dir=local_dir,\n",
    "    local_dir_use_symlinks=False  # This ensures actual files are downloaded, not symlinks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b02c6661-e842-4ab7-8a0f-99c1c755fc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE.md\t\t\tcell_type_onehot_map.pkl  pert_onehot_map.pt\n",
      "MODEL_ACCEPTABLE_USE_POLICY.md\tconfig.yaml\t\t  var_dims.pkl\n",
      "MODEL_LICENSE.md\t\tdata_module.torch\t  wandb_path.txt\n",
      "README.md\t\t\tfinal.ckpt\n",
      "batch_onehot_map.pkl\t\tfinal_from_preprint.ckpt\n"
     ]
    }
   ],
   "source": [
    "! ls virtual_cell/ST-Tahoe/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ca2fb0-8dfd-4a6b-8548-9da3eac71b99",
   "metadata": {},
   "source": [
    "## Inferecne our sample\n",
    "### Killed reason: 1.My MacPro (16G memory) might not enough memory for inference run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d35d638-4beb-4e30-b826-3a4fdec84d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:state._cli._tx._infer:Loaded config from virtual_cell/ST-Tahoe/config.yaml\n",
      "INFO:state._cli._tx._infer:Loading model from checkpoint: virtual_cell/ST-Tahoe/final.ckpt\n",
      "PertSetsPerturbationModel(\n",
      "  (loss_fn): SamplesLoss()\n",
      "  (gene_decoder): LatentToGeneDecoder(\n",
      "    (decoder): Sequential(\n",
      "      (0): Linear(in_features=2000, out_features=1024, bias=True)\n",
      "      (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (2): GELU(approximate='none')\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "      (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (5): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (6): GELU(approximate='none')\n",
      "      (7): Dropout(p=0.1, inplace=False)\n",
      "      (8): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (9): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (10): GELU(approximate='none')\n",
      "      (11): Dropout(p=0.1, inplace=False)\n",
      "      (12): Linear(in_features=512, out_features=2000, bias=True)\n",
      "      (13): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (pert_encoder): Sequential(\n",
      "    (0): Linear(in_features=1138, out_features=1488, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=1488, out_features=1488, bias=True)\n",
      "    (4): GELU(approximate='none')\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=1488, out_features=1488, bias=True)\n",
      "    (7): GELU(approximate='none')\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=1488, out_features=1488, bias=True)\n",
      "  )\n",
      "  (basal_encoder): Sequential(\n",
      "    (0): Linear(in_features=2000, out_features=1488, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=1488, out_features=1488, bias=True)\n",
      "    (4): GELU(approximate='none')\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=1488, out_features=1488, bias=True)\n",
      "    (7): GELU(approximate='none')\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=1488, out_features=1488, bias=True)\n",
      "  )\n",
      "  (transformer_backbone): LlamaBidirectionalModel(\n",
      "    (embed_tokens): Embedding(32000, 1488, padding_idx=0)\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=1488, out_features=1488, bias=False)\n",
      "          (k_proj): Linear(in_features=1488, out_features=1488, bias=False)\n",
      "          (v_proj): Linear(in_features=1488, out_features=1488, bias=False)\n",
      "          (o_proj): Linear(in_features=1488, out_features=1488, bias=False)\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=1488, out_features=5952, bias=False)\n",
      "          (up_proj): Linear(in_features=1488, out_features=5952, bias=False)\n",
      "          (down_proj): Linear(in_features=5952, out_features=1488, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((1488,), eps=1e-06)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((1488,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((1488,), eps=1e-06)\n",
      "    (rotary_emb): NoRoPE()\n",
      "  )\n",
      "  (project_out): Sequential(\n",
      "    (0): Linear(in_features=1488, out_features=1488, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=1488, out_features=1488, bias=True)\n",
      "    (4): GELU(approximate='none')\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=1488, out_features=1488, bias=True)\n",
      "    (7): GELU(approximate='none')\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=1488, out_features=2000, bias=True)\n",
      "  )\n",
      "  (batch_encoder): Embedding(14, 1488)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "INFO:state.tx.models.base:Loaded decoder from checkpoint decoder_cfg: {'latent_dim': 2000, 'gene_dim': 2000, 'hidden_dims': [1024, 1024, 512], 'dropout': 0.1, 'residual_decoder': False}\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/.local/bin/state\", line 10, in <module>\n",
      "    sys.exit(main())\n",
      "             ^^^^^^\n",
      "  File \"/root/.local/share/uv/tools/arc-state/lib/python3.11/site-packages/state/__main__.py\", line 68, in main\n",
      "    run_tx_infer(args)\n",
      "  File \"/root/.local/share/uv/tools/arc-state/lib/python3.11/site-packages/state/_cli/_tx/_infer.py\", line 76, in run_tx_infer\n",
      "    model = PertSetsPerturbationModel.load_from_checkpoint(checkpoint_path)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/tools/arc-state/lib/python3.11/site-packages/lightning/pytorch/utilities/model_helpers.py\", line 125, in wrapper\n",
      "    return self.method(cls, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/tools/arc-state/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1611, in load_from_checkpoint\n",
      "    loaded = _load_from_checkpoint(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/tools/arc-state/lib/python3.11/site-packages/lightning/pytorch/core/saving.py\", line 91, in _load_from_checkpoint\n",
      "    model = _load_state(cls, checkpoint, strict=strict, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/tools/arc-state/lib/python3.11/site-packages/lightning/pytorch/core/saving.py\", line 187, in _load_state\n",
      "    keys = obj.load_state_dict(checkpoint[\"state_dict\"], strict=strict)  # type: ignore[arg-type]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/tools/arc-state/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 2593, in load_state_dict\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Error(s) in loading state_dict for PertSetsPerturbationModel:\n",
      "\tMissing key(s) in state_dict: \"basal_encoder.0.weight\", \"basal_encoder.0.bias\", \"basal_encoder.3.weight\", \"basal_encoder.3.bias\", \"basal_encoder.6.weight\", \"basal_encoder.6.bias\", \"basal_encoder.9.weight\", \"basal_encoder.9.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"basal_encoder.weight\", \"basal_encoder.bias\". \n"
     ]
    }
   ],
   "source": [
    "! state tx infer \\\n",
    "  --output \"virtual_cell/prediction_ST-Tahoe_250902/prediction_only_10.h5ad\" \\\n",
    "  --model_dir virtual_cell/ST-Tahoe \\\n",
    "  --checkpoint virtual_cell/ST-Tahoe/final.ckpt \\\n",
    "  --adata \"virtual_cell/predicted_only_10.h5ad\" \\\n",
    "  --pert_col \"chemical\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e01f5a7-11e1-4f54-88f0-b68bc33a2600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:state._cli._emb._transform:Using model checkpoint: virtual_cell/SE-600M/se600m_epoch4.ckpt\n",
      "INFO:state._cli._emb._transform:Creating inference object\n",
      "INFO:state._cli._emb._transform:Loading model from checkpoint: virtual_cell/SE-600M/se600m_epoch4.ckpt\n",
      "Killed\n"
     ]
    }
   ],
   "source": [
    "# embedding first, but encounter the killed error. The moment memory used is 13G+, less than total 16 G. \n",
    "! state emb transform \\\n",
    "  --model-folder virtual_cell/SE-600M \\\n",
    "  --input virtual_cell/predicted_only_10.h5ad \\\n",
    "  --output virtual_cell/predicted_only_10_emb.h5ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f204abb-79aa-4403-8b38-1fe63a6ac821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:state._cli._tx._infer:Loaded config from virtual_cell/ST-Tahoe/config.yaml\n",
      "INFO:state._cli._tx._infer:Loading model from checkpoint: virtual_cell/ST-Tahoe/final.ckpt\n",
      "PertSetsPerturbationModel(\n",
      "  (loss_fn): SamplesLoss()\n",
      "  (gene_decoder): LatentToGeneDecoder(\n",
      "    (decoder): Sequential(\n",
      "      (0): Linear(in_features=2000, out_features=1024, bias=True)\n",
      "      (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (2): GELU(approximate='none')\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "      (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (5): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (6): GELU(approximate='none')\n",
      "      (7): Dropout(p=0.1, inplace=False)\n",
      "      (8): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (9): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (10): GELU(approximate='none')\n",
      "      (11): Dropout(p=0.1, inplace=False)\n",
      "      (12): Linear(in_features=512, out_features=2000, bias=True)\n",
      "      (13): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (pert_encoder): Sequential(\n",
      "    (0): Linear(in_features=1138, out_features=1488, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=1488, out_features=1488, bias=True)\n",
      "    (4): GELU(approximate='none')\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=1488, out_features=1488, bias=True)\n",
      "    (7): GELU(approximate='none')\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=1488, out_features=1488, bias=True)\n",
      "  )\n",
      "  (basal_encoder): Sequential(\n",
      "    (0): Linear(in_features=2000, out_features=1488, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=1488, out_features=1488, bias=True)\n",
      "    (4): GELU(approximate='none')\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=1488, out_features=1488, bias=True)\n",
      "    (7): GELU(approximate='none')\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=1488, out_features=1488, bias=True)\n",
      "  )\n",
      "  (transformer_backbone): LlamaBidirectionalModel(\n",
      "    (embed_tokens): Embedding(32000, 1488, padding_idx=0)\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=1488, out_features=1488, bias=False)\n",
      "          (k_proj): Linear(in_features=1488, out_features=1488, bias=False)\n",
      "          (v_proj): Linear(in_features=1488, out_features=1488, bias=False)\n",
      "          (o_proj): Linear(in_features=1488, out_features=1488, bias=False)\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=1488, out_features=5952, bias=False)\n",
      "          (up_proj): Linear(in_features=1488, out_features=5952, bias=False)\n",
      "          (down_proj): Linear(in_features=5952, out_features=1488, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((1488,), eps=1e-06)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((1488,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((1488,), eps=1e-06)\n",
      "    (rotary_emb): NoRoPE()\n",
      "  )\n",
      "  (project_out): Sequential(\n",
      "    (0): Linear(in_features=1488, out_features=1488, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=1488, out_features=1488, bias=True)\n",
      "    (4): GELU(approximate='none')\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=1488, out_features=1488, bias=True)\n",
      "    (7): GELU(approximate='none')\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=1488, out_features=2000, bias=True)\n",
      "  )\n",
      "  (batch_encoder): Embedding(14, 1488)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "INFO:state.tx.models.base:Loaded decoder from checkpoint decoder_cfg: {'latent_dim': 2000, 'gene_dim': 2000, 'hidden_dims': [1024, 1024, 512], 'dropout': 0.1, 'residual_decoder': False}\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/.local/bin/state\", line 10, in <module>\n",
      "    sys.exit(main())\n",
      "             ^^^^^^\n",
      "  File \"/root/.local/share/uv/tools/arc-state/lib/python3.11/site-packages/state/__main__.py\", line 68, in main\n",
      "    run_tx_infer(args)\n",
      "  File \"/root/.local/share/uv/tools/arc-state/lib/python3.11/site-packages/state/_cli/_tx/_infer.py\", line 76, in run_tx_infer\n",
      "    model = PertSetsPerturbationModel.load_from_checkpoint(checkpoint_path)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/tools/arc-state/lib/python3.11/site-packages/lightning/pytorch/utilities/model_helpers.py\", line 125, in wrapper\n",
      "    return self.method(cls, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/tools/arc-state/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1611, in load_from_checkpoint\n",
      "    loaded = _load_from_checkpoint(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/tools/arc-state/lib/python3.11/site-packages/lightning/pytorch/core/saving.py\", line 91, in _load_from_checkpoint\n",
      "    model = _load_state(cls, checkpoint, strict=strict, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/tools/arc-state/lib/python3.11/site-packages/lightning/pytorch/core/saving.py\", line 187, in _load_state\n",
      "    keys = obj.load_state_dict(checkpoint[\"state_dict\"], strict=strict)  # type: ignore[arg-type]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/tools/arc-state/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 2593, in load_state_dict\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Error(s) in loading state_dict for PertSetsPerturbationModel:\n",
      "\tMissing key(s) in state_dict: \"basal_encoder.0.weight\", \"basal_encoder.0.bias\", \"basal_encoder.3.weight\", \"basal_encoder.3.bias\", \"basal_encoder.6.weight\", \"basal_encoder.6.bias\", \"basal_encoder.9.weight\", \"basal_encoder.9.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"basal_encoder.weight\", \"basal_encoder.bias\". \n"
     ]
    }
   ],
   "source": [
    "# try a different input. NG official data\n",
    "! state tx infer \\\n",
    "  --output \"virtual_cell/prediction_ST-Tahoe_250902/prediction_competition_val_template.h5ad\" \\\n",
    "  --model_dir virtual_cell/ST-Tahoe \\\n",
    "  --checkpoint virtual_cell/ST-Tahoe/final.ckpt \\\n",
    "  --adata \"training_dataset/competition_support_set/competition_val_template.h5ad\" \\\n",
    "  --pert_col \"chemical\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60160cd2-9bd3-48a4-82a2-0459c2251b76",
   "metadata": {},
   "source": [
    "## Wrong model ST-Parse logs for learning structure for ours and COLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96dc00f4-6e53-43b1-9ec6-e03e25983d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:state._cli._tx._infer:Loaded config from virtual_cell/ST_Parse/config.yaml\n",
      "INFO:state._cli._tx._infer:Loading model from checkpoint: virtual_cell/ST_Parse/final.ckpt\n",
      "PertSetsPerturbationModel(\n",
      "  (loss_fn): SamplesLoss()\n",
      "  (gene_decoder): LatentToGeneDecoder(\n",
      "    (decoder): Sequential(\n",
      "      (0): Linear(in_features=2000, out_features=1024, bias=True)\n",
      "      (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (2): GELU(approximate='none')\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "      (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (5): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (6): GELU(approximate='none')\n",
      "      (7): Dropout(p=0.1, inplace=False)\n",
      "      (8): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (9): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (10): GELU(approximate='none')\n",
      "      (11): Dropout(p=0.1, inplace=False)\n",
      "      (12): Linear(in_features=512, out_features=2000, bias=True)\n",
      "      (13): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (pert_encoder): Sequential(\n",
      "    (0): Linear(in_features=91, out_features=1440, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "    (4): GELU(approximate='none')\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "    (7): GELU(approximate='none')\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "  )\n",
      "  (basal_encoder): Sequential(\n",
      "    (0): Linear(in_features=2000, out_features=1440, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "    (4): GELU(approximate='none')\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "    (7): GELU(approximate='none')\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "  )\n",
      "  (transformer_backbone): LlamaBidirectionalModel(\n",
      "    (embed_tokens): Embedding(32000, 1440, padding_idx=0)\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=1440, out_features=1440, bias=False)\n",
      "          (k_proj): Linear(in_features=1440, out_features=1440, bias=False)\n",
      "          (v_proj): Linear(in_features=1440, out_features=1440, bias=False)\n",
      "          (o_proj): Linear(in_features=1440, out_features=1440, bias=False)\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=1440, out_features=4416, bias=False)\n",
      "          (up_proj): Linear(in_features=1440, out_features=4416, bias=False)\n",
      "          (down_proj): Linear(in_features=4416, out_features=1440, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((1440,), eps=1e-06)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((1440,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((1440,), eps=1e-06)\n",
      "    (rotary_emb): NoRoPE()\n",
      "  )\n",
      "  (project_out): Sequential(\n",
      "    (0): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "    (4): GELU(approximate='none')\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "    (7): GELU(approximate='none')\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=1440, out_features=2000, bias=True)\n",
      "  )\n",
      "  (batch_encoder): Embedding(18, 1440)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "INFO:state.tx.models.base:Loaded decoder from checkpoint decoder_cfg: {'latent_dim': 2000, 'gene_dim': 2000, 'hidden_dims': [1024, 1024, 512], 'dropout': 0.1, 'residual_decoder': False}\n",
      "INFO:state._cli._tx._infer:Loading AnnData from: virtual_cell/predicted_only_10.h5ad\n",
      "INFO:state._cli._tx._infer:Using adata.X as input features: shape (500, 18080)\n",
      "INFO:state._cli._tx._infer:Perturbation tensor shape: torch.Size([500, 91])\n",
      "INFO:state._cli._tx._infer:Data module has 91 perturbations in mapping\n",
      "INFO:state._cli._tx._infer:First 10 perturbations in data module: [np.str_('4-1BBL'), np.str_('ADSF'), np.str_('APRIL'), np.str_('BAFF'), np.str_('C3a'), np.str_('C5a'), np.str_('CD27L'), np.str_('CD30L'), np.str_('CD40L'), np.str_('CT-1')]\n",
      "INFO:state._cli._tx._infer:AnnData has 50 unique perturbations\n",
      "INFO:state._cli._tx._infer:First 10 perturbations in AnnData: ['ACLY', 'ANXA6', 'ARPC2', 'CENPB', 'COX4I1', 'COX6C', 'CSK', 'CTSV', 'CXCL12', 'DOT1L']\n",
      "INFO:state._cli._tx._infer:Overlap between AnnData and data module: 0 perturbations\n",
      "WARNING:state._cli._tx._infer:Missing perturbations: ['SUPV3L1', 'UQCRB', 'COX4I1', 'MAT2A', 'EIF3H', 'MAX', 'CTSV', 'ACLY', 'KLHDC2', 'EHMT1']\n",
      "INFO:state._cli._tx._infer:Control perturbation in data module: 'PBS'\n",
      "INFO:state._cli._tx._infer:Matched 0 out of 500 perturbations\n",
      "INFO:state._cli._tx._infer:Running inference on 500 samples in 1 batches of size 512 (model's cell_sentence_len)...\n",
      "Processing samples:   0%|                          | 0/500 [00:00<?, ?samples/s]Traceback (most recent call last):\n",
      "  File \"/root/.local/bin/state\", line 10, in <module>\n",
      "    sys.exit(main())\n",
      "             ^^^^^^\n",
      "  File \"/root/.local/share/uv/tools/arc-state/lib/python3.11/site-packages/state/__main__.py\", line 68, in main\n",
      "    run_tx_infer(args)\n",
      "  File \"/root/.local/share/uv/tools/arc-state/lib/python3.11/site-packages/state/_cli/_tx/_infer.py\", line 203, in run_tx_infer\n",
      "    batch_preds = model.predict_step(batch, batch_idx=batch_idx, padded=False)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/tools/arc-state/lib/python3.11/site-packages/state/tx/models/pert_sets.py\", line 552, in predict_step\n",
      "    latent_output = self.forward(batch, padded=padded)  # shape [B, ...]\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/tools/arc-state/lib/python3.11/site-packages/state/tx/models/pert_sets.py\", line 297, in forward\n",
      "    basal = batch[\"ctrl_cell_emb\"].reshape(1, -1, self.input_dim)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: shape '[1, -1, 2000]' is invalid for input of size 9256960\n",
      "Processing samples:   0%|                          | 0/500 [00:00<?, ?samples/s]\n"
     ]
    }
   ],
   "source": [
    "! state tx infer \\\n",
    "  --output \"virtual_cell/prediction_250617/prediction_only_10.h5ad\" \\\n",
    "  --model_dir virtual_cell/ST_Parse \\\n",
    "  --checkpoint virtual_cell/ST_Parse/final.ckpt \\\n",
    "  --adata \"virtual_cell/predicted_only_10.h5ad\" \\\n",
    "  --pert_col \"target_gene\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71f6cc6-aecf-41b3-9ac8-c0f1e07aa8c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c10d444d-f5e5-4252-9c70-b77350f7632c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:state._cli._tx._infer:Loaded config from virtual_cell/ST_Parse/config.yaml\n",
      "INFO:state._cli._tx._infer:Loading model from checkpoint: virtual_cell/ST_Parse/final.ckpt\n",
      "PertSetsPerturbationModel(\n",
      "  (loss_fn): SamplesLoss()\n",
      "  (gene_decoder): LatentToGeneDecoder(\n",
      "    (decoder): Sequential(\n",
      "      (0): Linear(in_features=2000, out_features=1024, bias=True)\n",
      "      (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (2): GELU(approximate='none')\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "      (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (5): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (6): GELU(approximate='none')\n",
      "      (7): Dropout(p=0.1, inplace=False)\n",
      "      (8): Linear(in_features=1024, out_features=512, bias=True)\n",
      "      (9): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (10): GELU(approximate='none')\n",
      "      (11): Dropout(p=0.1, inplace=False)\n",
      "      (12): Linear(in_features=512, out_features=2000, bias=True)\n",
      "      (13): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (pert_encoder): Sequential(\n",
      "    (0): Linear(in_features=91, out_features=1440, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "    (4): GELU(approximate='none')\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "    (7): GELU(approximate='none')\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "  )\n",
      "  (basal_encoder): Sequential(\n",
      "    (0): Linear(in_features=2000, out_features=1440, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "    (4): GELU(approximate='none')\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "    (7): GELU(approximate='none')\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "  )\n",
      "  (transformer_backbone): LlamaBidirectionalModel(\n",
      "    (embed_tokens): Embedding(32000, 1440, padding_idx=0)\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=1440, out_features=1440, bias=False)\n",
      "          (k_proj): Linear(in_features=1440, out_features=1440, bias=False)\n",
      "          (v_proj): Linear(in_features=1440, out_features=1440, bias=False)\n",
      "          (o_proj): Linear(in_features=1440, out_features=1440, bias=False)\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=1440, out_features=4416, bias=False)\n",
      "          (up_proj): Linear(in_features=1440, out_features=4416, bias=False)\n",
      "          (down_proj): Linear(in_features=4416, out_features=1440, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((1440,), eps=1e-06)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((1440,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((1440,), eps=1e-06)\n",
      "    (rotary_emb): NoRoPE()\n",
      "  )\n",
      "  (project_out): Sequential(\n",
      "    (0): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "    (4): GELU(approximate='none')\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Linear(in_features=1440, out_features=1440, bias=True)\n",
      "    (7): GELU(approximate='none')\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Linear(in_features=1440, out_features=2000, bias=True)\n",
      "  )\n",
      "  (batch_encoder): Embedding(18, 1440)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "INFO:state.tx.models.base:Loaded decoder from checkpoint decoder_cfg: {'latent_dim': 2000, 'gene_dim': 2000, 'hidden_dims': [1024, 1024, 512], 'dropout': 0.1, 'residual_decoder': False}\n",
      "INFO:state._cli._tx._infer:Loading AnnData from: training_dataset/competition_support_set/competition_val_template.h5ad\n",
      "INFO:state._cli._tx._infer:Using adata.X as input features: shape (98927, 18080)\n",
      "INFO:state._cli._tx._infer:Perturbation tensor shape: torch.Size([98927, 91])\n",
      "INFO:state._cli._tx._infer:Data module has 91 perturbations in mapping\n",
      "INFO:state._cli._tx._infer:First 10 perturbations in data module: [np.str_('4-1BBL'), np.str_('ADSF'), np.str_('APRIL'), np.str_('BAFF'), np.str_('C3a'), np.str_('C5a'), np.str_('CD27L'), np.str_('CD30L'), np.str_('CD40L'), np.str_('CT-1')]\n",
      "INFO:state._cli._tx._infer:AnnData has 51 unique perturbations\n",
      "INFO:state._cli._tx._infer:First 10 perturbations in AnnData: ['ACLY', 'ANXA6', 'ARPC2', 'CENPB', 'COX4I1', 'COX6C', 'CSK', 'CTSV', 'CXCL12', 'DOT1L']\n",
      "INFO:state._cli._tx._infer:Overlap between AnnData and data module: 0 perturbations\n",
      "WARNING:state._cli._tx._infer:Missing perturbations: ['FUBP1', 'ACLY', 'ANXA6', 'SMARCB1', 'STRAP', 'HDAC8', 'SUPV3L1', 'HDAC3', 'MAT2A', 'TCF7L2']\n",
      "INFO:state._cli._tx._infer:Control perturbation in data module: 'PBS'\n",
      "INFO:state._cli._tx._infer:Matched 0 out of 98927 perturbations\n",
      "INFO:state._cli._tx._infer:Running inference on 98927 samples in 194 batches of size 512 (model's cell_sentence_len)...\n",
      "Processing samples:   0%|                        | 0/98927 [00:00<?, ?samples/s]Traceback (most recent call last):\n",
      "  File \"/root/.local/bin/state\", line 10, in <module>\n",
      "    sys.exit(main())\n",
      "             ^^^^^^\n",
      "  File \"/root/.local/share/uv/tools/arc-state/lib/python3.11/site-packages/state/__main__.py\", line 68, in main\n",
      "    run_tx_infer(args)\n",
      "  File \"/root/.local/share/uv/tools/arc-state/lib/python3.11/site-packages/state/_cli/_tx/_infer.py\", line 203, in run_tx_infer\n",
      "    batch_preds = model.predict_step(batch, batch_idx=batch_idx, padded=False)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/tools/arc-state/lib/python3.11/site-packages/state/tx/models/pert_sets.py\", line 552, in predict_step\n",
      "    latent_output = self.forward(batch, padded=padded)  # shape [B, ...]\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/.local/share/uv/tools/arc-state/lib/python3.11/site-packages/state/tx/models/pert_sets.py\", line 297, in forward\n",
      "    basal = batch[\"ctrl_cell_emb\"].reshape(1, -1, self.input_dim)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: shape '[1, -1, 2000]' is invalid for input of size 9256960\n",
      "Processing samples:   0%|                        | 0/98927 [00:02<?, ?samples/s]\n"
     ]
    }
   ],
   "source": [
    "# using COLAB input for testing\n",
    "! state tx infer \\\n",
    "  --output \"virtual_cell/prediction_250617/prediction_only_10.h5ad\" \\\n",
    "  --model_dir virtual_cell/ST_Parse \\\n",
    "  --checkpoint virtual_cell/ST_Parse/final.ckpt \\\n",
    "  --adata \"training_dataset/competition_support_set/competition_val_template.h5ad\" \\\n",
    "  --pert_col \"target_gene\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c94b19d-79cb-4f96-a5b7-e5e03d0e157f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30b5d36-776e-450b-a13e-014282f360b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01408d1-045f-4dd8-be37-467ddd4130fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699c5225-af4d-4771-975d-3ed7d33ff823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af66a223-2a8d-4885-b908-2746a003b02f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea10e3e-2de1-4d8d-b394-6339db28e0d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df4e32a-0a5a-499d-88ab-ad676f985868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdd165d-8175-4218-8fb5-9812a2d99e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16103607-09ba-47d5-9b7f-0a6c7d4554c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954fed52-5e2c-42df-bacb-495d03b94323",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
